{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNGeometry Gram matrix example",
      "provenance": [],
      "authorship_tag": "ABX9TyOIYSysTfMEp7ZIP0laQMbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tfjgeorge/nngeometry-examples/blob/main/Gram_matrix_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZvhzZJ6k4Tl",
        "outputId": "21e7c782-34ca-4968-b4fa-c5a810d078fd"
      },
      "source": [
        "!pip install git+https://github.com/tfjgeorge/nngeometry.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tfjgeorge/nngeometry.git\n",
            "  Cloning https://github.com/tfjgeorge/nngeometry.git to /tmp/pip-req-build-5c9pjjx3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tfjgeorge/nngeometry.git /tmp/pip-req-build-5c9pjjx3\n",
            "  Resolved https://github.com/tfjgeorge/nngeometry.git to commit d2a86ee06ef9ab7f7eb14fb4bd17a800f04b1c0c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from nngeometry==0.3.2) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from nngeometry==0.3.2) (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->nngeometry==0.3.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->nngeometry==0.3.2) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.9.1->nngeometry==0.3.2) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.9.1->nngeometry==0.3.2) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->nngeometry==0.3.2) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcEfRHHAnjas"
      },
      "source": [
        "# PyTorch dataloader and model definition\n",
        "\n",
        "In the next cells, this is just your regular model and dataloader definition using standard PyTorch classes. Nothing here is specific to NNGeometry.\n",
        "\n",
        "We now start by defining our model. We here use a ResNet18."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AndrmMIik5mR"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = self.conv2(out)\n",
        "        out = F.relu(out + self.shortcut(x))\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "model = ResNet18().cuda()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ8OylUVtPA3"
      },
      "source": [
        "Next, we define the dataloader on which we compute the Gram matrix. Notice the specifics:\n",
        "\n",
        "- in the `Dataloader` instantiation, we pass `shuffle=False` so that examples in the Gram matrix are arranged in a deterministic way, i.e. the first example in the Gram matrix is the first example in the Dataloader and so on.\n",
        "- We used a subset of 100 examples of the original test set, since the Gram matrix grows as $n^2$ with $n=$#examples.\n",
        "- In order to improve performance, we copied the dataset into GPU memory using the `to_tensordataset` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebSMtxcMn799",
        "outputId": "d4899e97-f221-4c88-a3b2-e2ece787d242"
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "testset = Subset(CIFAR10(root='/tmp', train=False, download=True,\n",
        "                         transform=transform), range(100))\n",
        "\n",
        "def to_tensordataset(dataset):\n",
        "    d = next(iter(DataLoader(dataset,\n",
        "                  batch_size=len(dataset))))\n",
        "    return TensorDataset(d[0].to('cuda'), d[1].to('cuda'))\n",
        "\n",
        "testloader = DataLoader(to_tensordataset(testset), batch_size=100, shuffle=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YALYiOTno-Ye"
      },
      "source": [
        "Now that we are done with everything on the PyTorch side, let's get to NNGeometry !\n",
        "\n",
        "# Computing a Gram matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nngeometry import GramMatrix"
      ],
      "metadata": {
        "id": "7Kgkt5vjWQW4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jttrl2Dko_Lh",
        "outputId": "83e2533a-0180-4c16-f916-85fc32101deb"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "K = GramMatrix(model=model, loader=testloader)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f'time: {end_time - start_time}s')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 39.092442750930786s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7JAsCJ0sZPY"
      },
      "source": [
        "`K` is a FMatDense object, we can convert to a PyTorch tensor with the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJqr-mdcsBPZ"
      },
      "source": [
        "K_torch = K.get_dense_tensor()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT3EMTB-syRL"
      },
      "source": [
        "`K_torch` is arranged as a 10 x 100 x 10 x 100 tensor since we are here using a 10 classes task with 100 examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9pKTm9EssO3",
        "outputId": "beab730f-595c-47ff-a41c-4f2a70fe7d8a"
      },
      "source": [
        "K_torch.size()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 100, 10, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}